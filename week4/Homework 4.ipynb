{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4\n",
    "### Theory Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**  Consider a layer in CNN that takes in a single channel input of 64 × 64, and has 96\n",
    "filters. In each of the following cases, compute the number of parameters that are learned in this\n",
    "layer. We assume that bias is present for each weight.\n",
    "\n",
    "[1] A convolution layer with filters of same size as the input.\n",
    "$$ Param = (ksize^2 + 1)*channel$$ \n",
    "$$ Param = (64^2 + 1) * 96 $$\n",
    "$$ Param = 393312 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64**2 + 1)* 96 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[2] A convolution layer with 8 × 8 filters with stride of 4\n",
    "\n",
    "$$ Param = (ksize)^2 * channel + bias $$\n",
    "$$ Param = (8^2 + 1) * 96 $$\n",
    "$$ Param = 6240 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8**2 + 1) * 96 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[3]. A convolution layer with 1 × 1 filter and a stride of 1\n",
    "\n",
    "$$ Param = (ksize)^2 * channel + bias $$\n",
    "$$ Param = (1^2+ 1) * 96  $$\n",
    "$$ Param = 192 $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** Suppose you would have a neuron which has an RBF kernel as activation function (remember\n",
    "the evil wolf? Drop your linear style of thoughts. Circumferential thoughts can be nice too.)\n",
    "\n",
    "$$ y = exp(-(x_1^2 + x_2^2)) + b$$\n",
    "\n",
    "with parameter b. _What would be the shapes realized by the set of points {$(x1, x2) : y((x1, x2)) =\n",
    "0$} as a function of b ? Explain in at most 2 sentences and/or a little math._\n",
    "\n",
    "$$ 0 = exp(-(x_1^2 + x_2^2)) + b $$\n",
    "\n",
    "$$ -b = exp(-(x_1^2 + x_2^2)) $$\n",
    "\n",
    "$$ -ln(-b) = x_1^2 + x_2^2 $$\n",
    "\n",
    "Therefore, it is a circle centered around the origin with radius $\\sqrt{-log(-b)}$. Obviously this is only valid when $b < 0$.\n",
    "\n",
    "---\n",
    "\n",
    "Supposed now we add weight, \n",
    "\n",
    "$$ y = exp(-(w_1x_1^2 + w_2x_2^2)) + b$$\n",
    "\n",
    "_what shapes can we realize now?  Explain in at most 5 sentences and/or a little math. You\n",
    "can make references to publicly available in the internet materials to explain._\n",
    "\n",
    "$$ -ln(-b) = w_1x_1^2 + w_2x_2^2 $$\n",
    "\n",
    "$$ -ln(-b) = \\frac{x_1^2}{w_1^{-1}} + \\frac{x_2^2}{w_2^{-1}} $$\n",
    "\n",
    "$$ 1 = \\frac{x_1^2}{-ln(-b) \\cdot w_1^{-1}} + \\frac{x_2^2}{-ln(-b) \\cdot w_2^{-1}} $$\n",
    "\n",
    "$$ 1 = \\left(\\frac{x_1}{ \\sqrt{-ln(-b) \\cdot w_1^{-1}}}\\right)^2 + \\left(\\frac{x_2}{\\sqrt{-ln(-b) \\cdot w_2^{-1}}}\\right)^2 $$\n",
    "\n",
    "hence it is an elipse, centered around the origin with radius $\\sqrt{-ln(-b) \\cdot w_1^{-1}}$ along the $x_1$ axis and radius $\\sqrt{-ln(-b) \\cdot w_2^{-1}}$ along the $x_2$ axis.\n",
    "\n",
    "---\n",
    "\n",
    "**Q3** Suppose you have five linear neurons neurons n1, . . . , n5, realizing above decision boundaries\n",
    "as shown in Figure 1. That is: for every decision boundary we have outputs are = 0.5 in the zones\n",
    "marked with red plusses, and = 0.2 in the zones marked with the blue minuses.\n",
    "\n",
    "![figure1](figure1.jpg)\n",
    "\n",
    "As you know,\n",
    "each neuron is realized by:\n",
    "\n",
    "$$ n_i = 0.3H(w^{(i)}_1x_1 + w^{(i)}_2 x_2 + b^{(i)}) + 0.2, \\quad H(z) ∈ {0, 1} $$\n",
    "\n",
    "where H is the threshold activation function. You want to predict positive values in a shape marked in green in Figure 1. You want to achieve this prediction by combining these neurons using a threshold neuron H:\n",
    "\n",
    "$$ y = H(\\sum_{i} v_i^* n_i + b^*) $$\n",
    "\n",
    "[1] _what do you have to do with the weights of $n_5$ so that you can move the decision boundary\n",
    "of $n_5$ so that you can realize the shape in green shown above (in the sense of having positive\n",
    "values inside and negative values outside.)? Give a qualitative description. Note: Give a\n",
    "qualitative description in 3 sentences at most. Note that there is an x- and an y-axis, which\n",
    "helps you to express vectors qualitatively._\n",
    "\n",
    "The position of the decision boundary of $n_5$ depends on its weight and biases. Particularly, the ratio between $w_1$ and $w_2$ determines the slant of the boundary, while the ratio between the $b$ and $w_2$ determines its offset from origin. As the desired position is a shift upwards (given that the boundary continues infinitely), we want to decrease $b$ so that the boundaries shift upwards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] _after moving the decision boundary of n5 appropriately, the green shape looks a bit like an\n",
    "logical AND-combination of the +-zones for every neuron. How to choose the weights $v^∗_i$ and the bias $b^∗$ in $ y = H(\\sum_{i} v_i^* n_i + b^*) $ so that you can realize the green shape (in the sense of having positive values inside and\n",
    "negative values outside that shape)? Note: $n_i$ gives out values either 0.5 or 0.2_\n",
    "\n",
    "Lets say that function $H$ has a threshold $h = 0$, such that\n",
    "\n",
    "$$ H(z) = 1[z > h] = 1[z > 0] $$\n",
    "\n",
    "If we were to take green area as {+1}, for the threshold neuron to fire $+1$, we will need all neurons $n_i$ to fire 0.5,\n",
    "\n",
    "$$ 1 = H(\\sum_{i} 0.5 v_i^* +b^*) $$\n",
    "\n",
    "$$ 1 = 1[(\\sum_{i} 0.5 v_i^* +b^*) > 0] $$\n",
    "\n",
    "$$ (\\sum_{i} 0.5 v_i^* +b^*) > 0 \\quad -- \\quad (1)$$\n",
    "\n",
    "If we were to take non-green area as {-1}, for the threshold neuron to fire $-1$, we will need at least one neuron $n_j$ to fire 0.2,\n",
    "\n",
    "$$ 0 = H(\\sum_{i-1}  v_i^* n_i + v_j^* n_j + b^*) $$\n",
    "\n",
    "$$ 0 = H(\\sum_{i-1}  0.5v_i^* + 0.2v_j^* + b^*) $$\n",
    "\n",
    "$$ 0 = 1[\\sum_{i-1}  0.5v_i^* + 0.2v_j^* + b^* > 0] $$\n",
    "\n",
    "$$ \\sum_{i-1}  0.5v_i^* + 0.2v_j^* + b^* <= 0 \\quad -- \\quad (2) $$\n",
    "\n",
    "For simplicity, we set $v_i^* = 1$ for all $i$. Finding $b$, \n",
    "\n",
    "$$ 0.5 \\cdot 5 +b^* > 0 \\quad -- \\quad (1)$$\n",
    "\n",
    "$$ 2.5 + b^* > 0 $$\n",
    "\n",
    "$$ b^* > -2.5 $$\n",
    "\n",
    "$$ 0.5 \\cdot 4 + 0.2 + b^* <= 0 \\quad -- \\quad (2) $$\n",
    "\n",
    "$$ 2.2 + b^* <= 0 $$\n",
    "\n",
    "$$ b^* <= -2.2 $$\n",
    "\n",
    "$$ therefore \\quad -2.5 < b <= -2.2 $$\n",
    "\n",
    "we can pick any $b$ within this range, e.g. $ b = -2.4 $ with our $ v_i^* = 1$, such that\n",
    "\n",
    "$$ H(\\sum_{i} 0.5  -2.4 ) = H(2.5 - 2.4) \\quad for\\space all\\space n_i = 0.5$$\n",
    "$$ = H(0.1) = 1[0.1 > 0] = 1 \\quad (green)$$\n",
    "\n",
    "$$ H(\\sum_{i-1} 0.5 + 0.2  -2.4 ) = H(2.2 - 2.4) \\quad for\\space four\\space n_i = 0.5 \\space and\\space one\\space n_j = 0.2$$\n",
    "$$ = H(-0.2) = 1[-0.2 > 0] = 0 \\quad (outside)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
